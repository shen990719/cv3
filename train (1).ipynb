{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decreased-climb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: mxnet in /mistgpu/site-packages (1.8.0.post0)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /mistgpu/site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.25.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.18.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: mxnet-cu100==1.8.0 in /mistgpu/site-packages (1.8.0)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /mistgpu/site-packages (from mxnet-cu100==1.8.0) (0.8.4)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100==1.8.0) (2.25.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100==1.8.0) (1.18.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100==1.8.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100==1.8.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100==1.8.0) (1.26.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100==1.8.0) (3.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "read 1200 examples\n",
      "read 387 examples\n",
      "(64, 3, 320, 480)\n",
      "(64, 320, 480)\n",
      "read 1200 examples\n",
      "read 387 examples\n",
      "training on [gpu(0)]\n",
      "epoch 1, loss 1.1703, train acc 0.756, test acc 0.800, time 22.5 sec\n",
      "epoch 2, loss 0.5035, train acc 0.844, test acc 0.846, time 17.8 sec\n",
      "epoch 3, loss 0.3800, train acc 0.876, test acc 0.855, time 17.9 sec\n",
      "epoch 4, loss 0.3212, train acc 0.892, test acc 0.861, time 18.2 sec\n",
      "epoch 5, loss 0.2744, train acc 0.907, test acc 0.867, time 18.0 sec\n",
      "\n",
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n",
      "<NDArray 384x320x3 @gpu(0)>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.misc' has no attribute 'toimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e5303b30a659>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outfile.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'scipy.misc' has no attribute 'toimage'"
     ]
    }
   ],
   "source": [
    "!pip install mxnet\n",
    "!pip install -U mxnet-cu100==1.8.0\n",
    "from PIL import Image\n",
    "from mxnet import gluon, image, nd\n",
    "from mxnet.gluon import data as gdata, utils as gutils\n",
    "import os\n",
    "import sys\n",
    "from mxnet import gluon, image, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, model_zoo, nn\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "import scipy.misc\n",
    "\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, image, init, nd\n",
    "from mxnet.contrib import text\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn, utils as gutils\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from skimage import io,data\n",
    "import PIL.Image\n",
    "import cv2\n",
    "\n",
    "def read_voc_images(root='..', is_train=True):\n",
    "    \"\"\"Read VOC images.\"\"\"\n",
    "    txt_fname = 'train.txt' if is_train else 'val.txt'\n",
    "    with open(txt_fname, 'r') as f:\n",
    "        images = f.read().split()\n",
    "    features, labels = [None] * len(images), [None] * len(images)\n",
    "    for i, fname in enumerate(images):\n",
    "        features[i] = image.imread('/home/mist/cv3/images/%s.jpg' % (fname))\n",
    "        labels[i] = image.imread(\n",
    "            '/home/mist/cv3/annotations_trainval/%s.png' % (fname))\n",
    "    return features, labels\n",
    "\n",
    "def evaluate_accuracy(data_iter, net, ctx=[mx.cpu()]):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    acc_sum, n = nd.array([0]), 0\n",
    "    for batch in data_iter:\n",
    "        features, labels, _ = _get_batch(batch, ctx)\n",
    "        for X, y in zip(features, labels):\n",
    "            y = y.astype('float32')\n",
    "            acc_sum += (net(X).argmax(axis=1) == y).sum().copyto(mx.cpu())\n",
    "            n += y.size\n",
    "        acc_sum.wait_to_read()\n",
    "    return acc_sum.asscalar() / n\n",
    "\n",
    "def show_images(imgs, num_rows, num_cols, scale=2):\n",
    "    \"\"\"Plot a list of images.\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            axes[i][j].imshow(imgs[i * num_cols + j].asnumpy())\n",
    "            axes[i][j].axes.get_xaxis().set_visible(False)\n",
    "            axes[i][j].axes.get_yaxis().set_visible(False)\n",
    "    return axes\n",
    "\n",
    "def voc_label_indices(colormap, colormap2label):\n",
    "    colormap = colormap.astype('int32')\n",
    "    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256\n",
    "           + colormap[:, :, 2])\n",
    "    return colormap2label[idx]\n",
    "\n",
    "def use_svg_display():\n",
    "    \"\"\"Use svg format to display plot in jupyter\"\"\"\n",
    "    display.set_matplotlib_formats('svg')\n",
    "    \n",
    "def voc_rand_crop(feature, label, height, width):\n",
    "    feature, rect = image.random_crop(feature, (width, height))\n",
    "    label = image.fixed_crop(label, *rect)\n",
    "    return feature, label\n",
    "    \n",
    "class VOCSegDataset(gdata.Dataset):\n",
    "    def __init__(self, is_train, crop_size, voc_dir, colormap2label):\n",
    "        self.rgb_mean = nd.array([0.485, 0.456, 0.406])\n",
    "        self.rgb_std = nd.array([0.229, 0.224, 0.225])\n",
    "        self.crop_size = crop_size\n",
    "        features, labels = read_voc_images(root=voc_dir, is_train=is_train)\n",
    "        self.features = [self.normalize_image(feature)\n",
    "                         for feature in self.filter(features)]\n",
    "        self.labels = self.filter(labels)\n",
    "        self.colormap2label = colormap2label\n",
    "        print('read ' + str(len(self.features)) + ' examples')\n",
    "\n",
    "    def normalize_image(self, img):\n",
    "        return (img.astype('float32') / 255 - self.rgb_mean) / self.rgb_std\n",
    "\n",
    "    def filter(self, imgs):\n",
    "        return [img for img in imgs if (\n",
    "            img.shape[0] >= self.crop_size[0] and\n",
    "            img.shape[1] >= self.crop_size[1])]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature, label = voc_rand_crop(self.features[idx], self.labels[idx],\n",
    "                                       *self.crop_size)\n",
    "        return (feature.transpose((2, 0, 1)),\n",
    "                voc_label_indices(label, self.colormap2label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),\n",
    "                      dtype='float32')\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return nd.array(weight)\n",
    "\n",
    "train_features, train_labels = read_voc_images()\n",
    "\n",
    "\n",
    "VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']\n",
    "\n",
    "\n",
    "VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]]\n",
    "def _get_batch(batch, ctx):\n",
    "    \"\"\"Return features and labels on ctx.\"\"\"\n",
    "    features, labels = batch\n",
    "    if labels.dtype != features.dtype:\n",
    "        labels = labels.astype(features.dtype)\n",
    "    return (gutils.split_and_load(features, ctx),\n",
    "            gutils.split_and_load(labels, ctx), features.shape[0])\n",
    "\n",
    "def set_figsize(figsize=(3.5, 2.5)):\n",
    "    \"\"\"Set matplotlib figure size.\"\"\"\n",
    "    use_svg_display()\n",
    "    plt.rcParams['figure.figsize'] = figsize                \n",
    "\n",
    "def try_all_gpus():\n",
    "    \"\"\"Return all available GPUs, or [mx.cpu()] if there is no GPU.\"\"\"\n",
    "    ctxes = []\n",
    "    try:\n",
    "        for i in range(16):\n",
    "            ctx = mx.gpu(i)\n",
    "            _ = nd.array([0], ctx=ctx)\n",
    "            ctxes.append(ctx)\n",
    "    except mx.base.MXNetError:\n",
    "        pass\n",
    "    if not ctxes:\n",
    "        ctxes = [mx.cpu()]\n",
    "    return ctxes\n",
    "\n",
    "def train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs):\n",
    "    \"\"\"Train and evaluate a model.\"\"\"\n",
    "    print('training on', ctx)\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, m, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for i, batch in enumerate(train_iter):\n",
    "            Xs, ys, batch_size = _get_batch(batch, ctx)   \n",
    "            with autograd.record():\n",
    "                y_hats = [net(X) for X in Xs]\n",
    "                ls = [loss(y_hat, y) for y_hat, y in zip(y_hats, ys)]\n",
    "            for l in ls:\n",
    "                l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_l_sum += sum([l.sum().asscalar() for l in ls])\n",
    "            n += sum([l.size for l in ls])\n",
    "            train_acc_sum += sum([(y_hat.argmax(axis=1) == y).sum().asscalar()\n",
    "                                 for y_hat, y in zip(y_hats, ys)])\n",
    "            m += sum([y.size for y in ys])\n",
    "        test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / m, test_acc,\n",
    "                 time.time() - start))\n",
    "\n",
    "voc_dir='/home/mist/cv3/images'    \n",
    "colormap2label = nd.zeros(256 ** 3)\n",
    "for i, colormap in enumerate(VOC_COLORMAP):\n",
    "    colormap2label[(colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i\n",
    "    \n",
    "\n",
    "    \n",
    "imgs = []\n",
    "for _ in range(0,2100):\n",
    "    imgs += voc_rand_crop(train_features[0], train_labels[0], 200, 300)\n",
    "crop_size = (320, 480)\n",
    "voc_train = VOCSegDataset(True, crop_size, voc_dir, colormap2label)\n",
    "voc_test = VOCSegDataset(False, crop_size, voc_dir, colormap2label)\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "train_iter = gdata.DataLoader(voc_train, batch_size, shuffle=True,\n",
    "                              last_batch='discard', num_workers=num_workers)\n",
    "test_iter = gdata.DataLoader(voc_test, batch_size, last_batch='discard',\n",
    "                             num_workers=num_workers)\n",
    "for X, Y in train_iter:\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    break\n",
    "    \n",
    "X = nd.arange(1, 17).reshape((1, 1, 4, 4))\n",
    "K = nd.arange(1, 10).reshape((1, 1, 3, 3))\n",
    "conv = nn.Conv2D(channels=1, kernel_size=3)\n",
    "conv.initialize(init.Constant(K))\n",
    "conv(X), K\n",
    "\n",
    "W, k = nd.zeros((4, 16)), nd.zeros(11)\n",
    "k[:3], k[4:7], k[8:] = K[0, 0, 0, :], K[0, 0, 1, :], K[0, 0, 2, :]\n",
    "W[0, 0:11], W[1, 1:12], W[2, 4:15], W[3, 5:16] = k, k, k, k\n",
    "nd.dot(W, X.reshape(16)).reshape((1, 1, 2, 2)), W\n",
    "\n",
    "conv = nn.Conv2D(10, kernel_size=4, padding=1, strides=2)\n",
    "conv.initialize()\n",
    "\n",
    "X = nd.random.uniform(shape=(1, 3, 64, 64))\n",
    "Y = conv(X)\n",
    "Y.shape\n",
    "\n",
    "\n",
    "pretrained_net = model_zoo.vision.resnet18_v2(pretrained=True)\n",
    "pretrained_net.features[-4:], pretrained_net.output\n",
    "\n",
    "\n",
    "net = nn.HybridSequential()\n",
    "for layer in pretrained_net.features[:-2]:\n",
    "    net.add(layer)\n",
    "\n",
    "\n",
    "X = nd.random.uniform(shape=(1, 3, 320, 480))\n",
    "net(X).shape\n",
    "\n",
    "num_classes = 21\n",
    "net.add(nn.Conv2D(num_classes, kernel_size=1),\n",
    "        nn.Conv2DTranspose(num_classes, kernel_size=64, padding=16,\n",
    "                           strides=32))\n",
    "\n",
    "conv_trans = nn.Conv2DTranspose(3, kernel_size=4, padding=1, strides=2)\n",
    "conv_trans.initialize(init.Constant(bilinear_kernel(3, 3, 4)))\n",
    "\n",
    "\n",
    "set_figsize()\n",
    "\n",
    "\n",
    "net[-1].initialize(init.Constant(bilinear_kernel(num_classes, num_classes,64)))\n",
    "net[-2].initialize(init=init.Xavier())\n",
    "\n",
    "crop_size, batch_size, colormap2label = (320, 480), 32, nd.zeros(256**3)\n",
    "for i, cm in enumerate(VOC_COLORMAP):\n",
    "    colormap2label[(cm[0] * 256 + cm[1]) * 256 + cm[2]] = i\n",
    "voc_dir = \"/content/drive/MyDrive/images\"\n",
    "\n",
    "num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "train_iter = gdata.DataLoader(\n",
    "    VOCSegDataset(True, crop_size, voc_dir, colormap2label), batch_size,\n",
    "    shuffle=True, last_batch='discard', num_workers=num_workers)\n",
    "test_iter = gdata.DataLoader(\n",
    "    VOCSegDataset(False, crop_size, voc_dir, colormap2label), batch_size,\n",
    "    last_batch='discard', num_workers=num_workers)\n",
    "\n",
    "ctx =try_all_gpus()\n",
    "loss = gloss.SoftmaxCrossEntropyLoss(axis=1)\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1,'wd': 1e-3})\n",
    "train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs=5)\n",
    "\n",
    "def predict(img):\n",
    "    X = test_iter._dataset.normalize_image(img)\n",
    "    X = X.transpose((2, 0, 1)).expand_dims(axis=0)\n",
    "    pred = nd.argmax(net(X.as_in_context(ctx[0])), axis=1)\n",
    "    return pred.reshape((pred.shape[1], pred.shape[2]))\n",
    "    \n",
    "def label2image(pred):\n",
    "    colormap = nd.array(VOC_COLORMAP, ctx=ctx[0], dtype='uint8')\n",
    "    X = pred.astype('int32')\n",
    "    return colormap[X, :]\n",
    "\n",
    "for i in range(2100,2101):\n",
    "    features= image.imread('/home/mist/cv3/images/%s.jpg' % (i))\n",
    "    im = Image.open('/home/mist/cv3/images/%s.jpg' % (i))\n",
    "    crop_rect = (0, 0,320,480)\n",
    "    X = image.fixed_crop(features, *crop_rect)\n",
    "    pred = label2image(predict(X))\n",
    "    print(pred)\n",
    "    \n",
    "    scipy.misc.toimage(pred, cmin=0.0, cmax=...).save('outfile.jpg')\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mxnet\n",
    "!pip install -U mxnet-cu100==1.8.0\n",
    "\n",
    "from mxnet import gluon, image, nd\n",
    "from mxnet.gluon import data as gdata, utils as gutils\n",
    "import os\n",
    "import sys\n",
    "from mxnet import gluon, image, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, model_zoo, nn\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, image, init, nd\n",
    "from mxnet.contrib import text\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn, utils as gutils\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_voc_images(root='..', is_train=True):\n",
    "    \"\"\"Read VOC images.\"\"\"\n",
    "    txt_fname = 'train.txt' if is_train else 'val.txt'\n",
    "    with open(txt_fname, 'r') as f:\n",
    "        images = f.read().split()\n",
    "    features, labels = [None] * len(images), [None] * len(images)\n",
    "    for i, fname in enumerate(images):\n",
    "        features[i] = image.imread('/home/mist/cv3/images/%s.jpg' % (fname))\n",
    "        labels[i] = image.imread(\n",
    "            '/home/mist/cv3/annotations_trainval/%s.png' % (fname))\n",
    "    return features, labels\n",
    "\n",
    "def evaluate_accuracy(data_iter, net, ctx=[mx.cpu()]):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    acc_sum, n = nd.array([0]), 0\n",
    "    for batch in data_iter:\n",
    "        features, labels, _ = _get_batch(batch, ctx)\n",
    "        for X, y in zip(features, labels):\n",
    "            y = y.astype('float32')\n",
    "            acc_sum += (net(X).argmax(axis=1) == y).sum().copyto(mx.cpu())\n",
    "            n += y.size\n",
    "        acc_sum.wait_to_read()\n",
    "    return acc_sum.asscalar() / n\n",
    "\n",
    "def show_images(imgs, num_rows, num_cols, scale=2):\n",
    "    \"\"\"Plot a list of images.\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            axes[i][j].imshow(imgs[i * num_cols + j].asnumpy())\n",
    "            axes[i][j].axes.get_xaxis().set_visible(False)\n",
    "            axes[i][j].axes.get_yaxis().set_visible(False)\n",
    "    return axes\n",
    "\n",
    "def voc_label_indices(colormap, colormap2label):\n",
    "    colormap = colormap.astype('int32')\n",
    "    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256\n",
    "           + colormap[:, :, 2])\n",
    "    return colormap2label[idx]\n",
    "\n",
    "def use_svg_display():\n",
    "    \"\"\"Use svg format to display plot in jupyter\"\"\"\n",
    "    display.set_matplotlib_formats('svg')\n",
    "    \n",
    "def voc_rand_crop(feature, label, height, width):\n",
    "    feature, rect = image.random_crop(feature, (width, height))\n",
    "    label = image.fixed_crop(label, *rect)\n",
    "    return feature, label\n",
    "    \n",
    "class VOCSegDataset(gdata.Dataset):\n",
    "    def __init__(self, is_train, crop_size, voc_dir, colormap2label):\n",
    "        self.rgb_mean = nd.array([0.485, 0.456, 0.406])\n",
    "        self.rgb_std = nd.array([0.229, 0.224, 0.225])\n",
    "        self.crop_size = crop_size\n",
    "        features, labels = read_voc_images(root=voc_dir, is_train=is_train)\n",
    "        self.features = [self.normalize_image(feature)\n",
    "                         for feature in self.filter(features)]\n",
    "        self.labels = self.filter(labels)\n",
    "        self.colormap2label = colormap2label\n",
    "        print('read ' + str(len(self.features)) + ' examples')\n",
    "\n",
    "    def normalize_image(self, img):\n",
    "        return (img.astype('float32') / 255 - self.rgb_mean) / self.rgb_std\n",
    "\n",
    "    def filter(self, imgs):\n",
    "        return [img for img in imgs if (\n",
    "            img.shape[0] >= self.crop_size[0] and\n",
    "            img.shape[1] >= self.crop_size[1])]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature, label = voc_rand_crop(self.features[idx], self.labels[idx],\n",
    "                                       *self.crop_size)\n",
    "        return (feature.transpose((2, 0, 1)),\n",
    "                voc_label_indices(label, self.colormap2label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),\n",
    "                      dtype='float32')\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return nd.array(weight)\n",
    "\n",
    "train_features, train_labels = read_voc_images()\n",
    "\n",
    "\n",
    "VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']\n",
    "\n",
    "\n",
    "VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]]\n",
    "def _get_batch(batch, ctx):\n",
    "    \"\"\"Return features and labels on ctx.\"\"\"\n",
    "    features, labels = batch\n",
    "    if labels.dtype != features.dtype:\n",
    "        labels = labels.astype(features.dtype)\n",
    "    return (gutils.split_and_load(features, ctx),\n",
    "            gutils.split_and_load(labels, ctx), features.shape[0])\n",
    "\n",
    "def set_figsize(figsize=(3.5, 2.5)):\n",
    "    \"\"\"Set matplotlib figure size.\"\"\"\n",
    "    use_svg_display()\n",
    "    plt.rcParams['figure.figsize'] = figsize                \n",
    "\n",
    "def try_all_gpus():\n",
    "    \"\"\"Return all available GPUs, or [mx.cpu()] if there is no GPU.\"\"\"\n",
    "    ctxes = []\n",
    "    try:\n",
    "        for i in range(16):\n",
    "            ctx = mx.gpu(i)\n",
    "            _ = nd.array([0], ctx=ctx)\n",
    "            ctxes.append(ctx)\n",
    "    except mx.base.MXNetError:\n",
    "        pass\n",
    "    if not ctxes:\n",
    "        ctxes = [mx.cpu()]\n",
    "    return ctxes\n",
    "\n",
    "def train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs):\n",
    "    \"\"\"Train and evaluate a model.\"\"\"\n",
    "    print('training on', ctx)\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, m, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for i, batch in enumerate(train_iter):\n",
    "            Xs, ys, batch_size = _get_batch(batch, ctx)   \n",
    "            with autograd.record():\n",
    "                y_hats = [net(X) for X in Xs]\n",
    "                ls = [loss(y_hat, y) for y_hat, y in zip(y_hats, ys)]\n",
    "            for l in ls:\n",
    "                l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_l_sum += sum([l.sum().asscalar() for l in ls])\n",
    "            n += sum([l.size for l in ls])\n",
    "            train_acc_sum += sum([(y_hat.argmax(axis=1) == y).sum().asscalar()\n",
    "                                 for y_hat, y in zip(y_hats, ys)])\n",
    "            m += sum([y.size for y in ys])\n",
    "        test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / m, test_acc,\n",
    "                 time.time() - start))\n",
    "\n",
    "voc_dir='/home/mist/cv3/images'    \n",
    "colormap2label = nd.zeros(256 ** 3)\n",
    "for i, colormap in enumerate(VOC_COLORMAP):\n",
    "    colormap2label[(colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i\n",
    "    \n",
    "\n",
    "    \n",
    "imgs = []\n",
    "for _ in range(0,2100):\n",
    "    imgs += voc_rand_crop(train_features[0], train_labels[0], 200, 300)\n",
    "crop_size = (320, 480)\n",
    "voc_train = VOCSegDataset(True, crop_size, voc_dir, colormap2label)\n",
    "voc_test = VOCSegDataset(False, crop_size, voc_dir, colormap2label)\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "train_iter = gdata.DataLoader(voc_train, batch_size, shuffle=True,\n",
    "                              last_batch='discard', num_workers=num_workers)\n",
    "test_iter = gdata.DataLoader(voc_test, batch_size, last_batch='discard',\n",
    "                             num_workers=num_workers)\n",
    "for X, Y in train_iter:\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    break\n",
    "    \n",
    "X = nd.arange(1, 17).reshape((1, 1, 4, 4))\n",
    "K = nd.arange(1, 10).reshape((1, 1, 3, 3))\n",
    "conv = nn.Conv2D(channels=1, kernel_size=3)\n",
    "conv.initialize(init.Constant(K))\n",
    "conv(X), K\n",
    "\n",
    "W, k = nd.zeros((4, 16)), nd.zeros(11)\n",
    "k[:3], k[4:7], k[8:] = K[0, 0, 0, :], K[0, 0, 1, :], K[0, 0, 2, :]\n",
    "W[0, 0:11], W[1, 1:12], W[2, 4:15], W[3, 5:16] = k, k, k, k\n",
    "nd.dot(W, X.reshape(16)).reshape((1, 1, 2, 2)), W\n",
    "\n",
    "conv = nn.Conv2D(10, kernel_size=4, padding=1, strides=2)\n",
    "conv.initialize()\n",
    "\n",
    "X = nd.random.uniform(shape=(1, 3, 64, 64))\n",
    "Y = conv(X)\n",
    "Y.shape\n",
    "\n",
    "\n",
    "pretrained_net = model_zoo.vision.resnet18_v2(pretrained=True)\n",
    "pretrained_net.features[-4:], pretrained_net.output\n",
    "\n",
    "\n",
    "net = nn.HybridSequential()\n",
    "for layer in pretrained_net.features[:-2]:\n",
    "    net.add(layer)\n",
    "\n",
    "\n",
    "X = nd.random.uniform(shape=(1, 3, 320, 480))\n",
    "net(X).shape\n",
    "\n",
    "num_classes = 21\n",
    "net.add(nn.Conv2D(num_classes, kernel_size=1),\n",
    "        nn.Conv2DTranspose(num_classes, kernel_size=64, padding=16,\n",
    "                           strides=32))\n",
    "\n",
    "conv_trans = nn.Conv2DTranspose(3, kernel_size=4, padding=1, strides=2)\n",
    "conv_trans.initialize(init.Constant(bilinear_kernel(3, 3, 4)))\n",
    "\n",
    "\n",
    "set_figsize()\n",
    "\n",
    "\n",
    "net[-1].initialize(init.Constant(bilinear_kernel(num_classes, num_classes,64)))\n",
    "net[-2].initialize(init=init.Xavier())\n",
    "\n",
    "crop_size, batch_size, colormap2label = (320, 480), 32, nd.zeros(256**3)\n",
    "for i, cm in enumerate(VOC_COLORMAP):\n",
    "    colormap2label[(cm[0] * 256 + cm[1]) * 256 + cm[2]] = i\n",
    "voc_dir = \"/content/drive/MyDrive/images\"\n",
    "\n",
    "num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "train_iter = gdata.DataLoader(\n",
    "    VOCSegDataset(True, crop_size, voc_dir, colormap2label), batch_size,\n",
    "    shuffle=True, last_batch='discard', num_workers=num_workers)\n",
    "test_iter = gdata.DataLoader(\n",
    "    VOCSegDataset(False, crop_size, voc_dir, colormap2label), batch_size,\n",
    "    last_batch='discard', num_workers=num_workers)\n",
    "\n",
    "ctx =try_all_gpus()\n",
    "loss = gloss.SoftmaxCrossEntropyLoss(axis=1)\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1,'wd': 1e-3})\n",
    "train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs=5)\n",
    "\n",
    "def predict(img):\n",
    "    X = test_iter._dataset.normalize_image(img)\n",
    "    X = X.transpose((2, 0, 1)).expand_dims(axis=0)\n",
    "    pred = nd.argmax(net(X.as_in_context(ctx[0])), axis=1)\n",
    "    return pred.reshape((pred.shape[1], pred.shape[2]))\n",
    "    \n",
    "def label2image(pred):\n",
    "    colormap = nd.array(VOC_COLORMAP, ctx=ctx[0], dtype='uint8')\n",
    "    X = pred.astype('int32')\n",
    "    return colormap[X, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-technician",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-sailing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
